###album catalog: cellcanvas

from album.runner.api import setup, get_data_path, get_args

env_file = """name: segmentation-env
channels:
  - conda-forge
  - defaults
dependencies:
  - python=3.10
  - scikit-learn==1.3.2
  - joblib
  - numpy
  - zarr
  - pip
"""

def run():
    import os
    import joblib
    import numpy as np
    import zarr
    from sklearn.ensemble import RandomForestClassifier

    def load_model(model_path):
        """Load the random forest model from a joblib file."""
        return joblib.load(model_path)

    def apply_model_to_embeddings_in_chunks(embeddings_path, model, chunk_size, output_path):
        """Load embeddings from Zarr in chunks, apply the model, and save predictions to a new Zarr file."""
        zarr_embeddings = zarr.open(embeddings_path, mode='r')
        output_zarr = zarr.open(output_path, shape=zarr_embeddings.shape[:-1], chunks=(chunk_size, chunk_size, chunk_size), dtype=int, mode='w')

        # Determine the number of chunks needed along each dimension
        chunks = [range(0, dim, chunk_size) for dim in zarr_embeddings.shape[:-1]]

        for x in chunks[0]:
            for y in chunks[1]:
                for z in chunks[2]:
                    # Define the current chunk's slice
                    current_slice = (slice(x, min(x + chunk_size, zarr_embeddings.shape[0])),
                                     slice(y, min(y + chunk_size, zarr_embeddings.shape[1])),
                                     slice(z, min(z + chunk_size, zarr_embeddings.shape[2])))
                    
                    # Load the current chunk
                    chunk = zarr_embeddings[current_slice]
                    # Reshape for prediction and adjust dimensions
                    chunk_reshaped = chunk.reshape(-1, chunk.shape[-1])
                    predictions = model.predict(chunk_reshaped).reshape(chunk.shape[:-1])
                    # Save predictions for the current chunk
                    output_zarr[current_slice] = predictions + 1  # Shift labels +1 for background handling

    # Arguments and model loading
    embeddings_path = get_args().zarrembedding
    model_path = get_args().modelpath  # Model path argument
    output_path = get_args().zarroutput
    chunk_size = 200  # Default chunk size

    model = load_model(model_path)
    apply_model_to_embeddings_in_chunks(embeddings_path, model, chunk_size, output_path)

    print(f"Segmentation output saved to {output_path}")

setup(
    group="cellcanvas",
    name="segment-tomogram",
    version="0.0.3",
    title="Segmentation using Random Forest on Embeddings in Chunks",
    description="Apply a Random Forest model to embeddings generated by TomoTwin to produce segmentation output, processing in chunks.",
    solution_creators=["Kyle Harrington"],
    cite=[{"text": "CellCanvas team.", "url": "https://cellcanvas.org"}],
    tags=["segmentation", "random forest", "machine learning", "cryoet", "chunks"],
    license="MIT",
    covers=[],
    album_api_version="0.5.1",
    args=[
        {"name": "zarrembedding", "type": "string", "required": True, "description": "Path to the input Zarr file containing embeddings"},
        {"name": "zarroutput", "type": "string", "required": True, "description": "Path for the output Zarr file containing segmentation"},
        {"name": "modelpath", "type": "string", "required": True, "description": "Path to the joblib file containing the trained Random Forest model"},
    ],
    run=run,
    install=None,  # Assuming all dependencies are covered by the environment
    dependencies={
        "environment_file": env_file
    },
)
