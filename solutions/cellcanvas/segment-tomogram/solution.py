###album catalog: cellcanvas

from album.runner.api import setup, get_data_path, get_args

env_file = """name: segmentation-env
channels:
  - conda-forge
  - defaults
dependencies:
  - python=3.10
  - scikit-learn==1.3.2
  - joblib
  - numpy
  - zarr
  - pip
"""

def run():
    import os
    import joblib
    import numpy as np
    import zarr

    def load_model(model_path):
        """Load the random forest model from a joblib file."""
        return joblib.load(model_path)

    def apply_model_to_embeddings_in_chunks(embeddings_path, model, chunk_size, output_path):
        """Load embeddings from Zarr in chunks, apply the model, and correctly handle transposed predictions."""
        zarr_embeddings = zarr.open(embeddings_path, mode='r')
        output_zarr = zarr.open(output_path, shape=np.transpose(zarr_embeddings.shape[:-1]), chunks=(chunk_size, chunk_size, chunk_size), dtype=int, mode='w')

        # Adjusted for clarity: indices for input and output need to respect the data's orientation
        for x in range(0, zarr_embeddings.shape[0], chunk_size):
            for y in range(0, zarr_embeddings.shape[1], chunk_size):
                for z in range(0, zarr_embeddings.shape[2], chunk_size):
                    # Fetching input: Use original indices
                    input_slice = (slice(x, min(x + chunk_size, zarr_embeddings.shape[0])),
                                   slice(y, min(y + chunk_size, zarr_embeddings.shape[1])),
                                   slice(z, min(z + chunk_size, zarr_embeddings.shape[2])))

                    chunk = zarr_embeddings[input_slice]
                    chunk_reshaped = chunk.reshape(-1, chunk.shape[-1])
                    predictions = model.predict(chunk_reshaped)

                    # Reshape predictions to match input chunk's shape
                    predictions_reshaped = predictions.reshape(chunk.shape[:-1])

                    # Transpose operation to align with full array's transpose requirement
                    predictions_transposed = np.transpose(predictions_reshaped, (2, 1, 0))  # Correct axes order after transpose

                    # Writing output: Indices should reflect transposed shape
                    # Since predictions_transposed swaps x and z axes, adjust output_slice accordingly
                    output_slice = (slice(z, min(z + chunk_size, output_zarr.shape[0])),
                                    slice(y, min(y + chunk_size, output_zarr.shape[1])),
                                    slice(x, min(x + chunk_size, output_zarr.shape[2])))

                    # Ensure output_slice fits within the output_zarr bounds (especially important for edges)
                    adjusted_output_slice = tuple(slice(s.start, min(s.stop, output_zarr.shape[dim])) for dim, s in enumerate(output_slice))

                    output_zarr[adjusted_output_slice] = predictions_transposed


    # Paths and model loading
    embeddings_path = get_args().zarrembedding
    model_path = get_args().modelpath
    output_path = get_args().zarroutput

    model = load_model(model_path)
    apply_model_to_embeddings_in_chunks(embeddings_path, model, output_path)

    print(f"Segmentation output saved to {output_path}")


setup(
    group="cellcanvas",
    name="segment-tomogram",
    version="0.0.4",
    title="Segmentation using Random Forest on Embeddings in Chunks",
    description="Apply a Random Forest model to embeddings generated by TomoTwin to produce segmentation output, processing in chunks.",
    solution_creators=["Kyle Harrington"],
    cite=[{"text": "CellCanvas team.", "url": "https://cellcanvas.org"}],
    tags=["segmentation", "random forest", "machine learning", "cryoet", "chunks"],
    license="MIT",
    covers=[],
    album_api_version="0.5.1",
    args=[
        {"name": "zarrembedding", "type": "string", "required": True, "description": "Path to the input Zarr file containing embeddings"},
        {"name": "zarroutput", "type": "string", "required": True, "description": "Path for the output Zarr file containing segmentation"},
        {"name": "modelpath", "type": "string", "required": True, "description": "Path to the joblib file containing the trained Random Forest model"},
    ],
    run=run,
    dependencies={
        "environment_file": env_file
    },
)
